{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning"
      ],
      "metadata": {
        "id": "tl5ZjF5R61D_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words Extraction"
      ],
      "metadata": {
        "id": "_ELi2Mmt66gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load your dataset\n",
        "twitter_df = pd.read_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/clean_twitter.csv')\n",
        "# Load your dataset\n",
        "insta_df = pd.read_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/clean_insta.csv')\n",
        "#rename column\n",
        "twitter_df.rename(columns={\"joined_text\":\"text\"},inplace=True)\n",
        "#rename column\n",
        "insta_df.rename(columns={\"joined_text\":\"text\"},inplace=True)"
      ],
      "metadata": {
        "id": "zDvVabvchE5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with NaN values from 'text' column\n",
        "insta_df.dropna(subset=['text'], inplace=True)"
      ],
      "metadata": {
        "id": "d89rxitth0Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating training datasets and test sets for each platform dataset"
      ],
      "metadata": {
        "id": "DXUALOsmUcT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_twitter_df, test_twitter_df = train_test_split(twitter_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the subsets as CSV files\n",
        "train_twitter_df.to_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/twitter_train.csv', index=False)\n",
        "test_twitter_df.to_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/twitter_test.csv', index=False)"
      ],
      "metadata": {
        "id": "3ynHww0HUtQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_insta_df, test_insta_df = train_test_split(insta_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the subsets as CSV files\n",
        "train_insta_df.to_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/insta_train.csv', index=False)\n",
        "test_insta_df.to_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/insta_test.csv', index=False)"
      ],
      "metadata": {
        "id": "bDcCWkaBU-wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_df = pd.read_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/twitter_train.csv')\n",
        "insta_df = pd.read_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/insta_train.csv')"
      ],
      "metadata": {
        "id": "MpCZEPRSVNgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subsample the Twitter Dataset: Randomly sample a subset of the Twitter dataset to match the size of the Instagram dataset. This ensures that both datasets contribute equally to the combined dataset."
      ],
      "metadata": {
        "id": "rdnq9Az0gdYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_subset = twitter_df.sample(n=len(insta_df), random_state=42)\n",
        "combined_df = pd.concat([twitter_subset, insta_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "CLjFdA_NgZbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM Count Vectorizer"
      ],
      "metadata": {
        "id": "4ly-bB99a6hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = combined_df['text']\n",
        "# #encode for train\n",
        "y,class_names = pd.factorize(combined_df['label'])\n",
        "\n",
        "# Splitting the data into 80-20 train-test split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_3V8k3W7D58",
        "outputId": "71edb8df-e8fb-488b-af29-0a5e063c73a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7180,)\n",
            "(1796,)\n",
            "(7180,)\n",
            "(1796,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the class names and their corresponding codes\n",
        "for code, class_name in enumerate(class_names):\n",
        "    print(f\"Code {code} represents class '{class_name}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2WCbYRNWmWe",
        "outputId": "7dc0c0ed-b244-4e4e-86ca-30b6ddaa81eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code 0 represents class 'cyberbullying'\n",
            "Code 1 represents class 'non-cyberbullying'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply CountVectorizer to text data\n",
        "count_vectorizer = CountVectorizer(max_features=5000) # max_features\n",
        "X_train_counts = count_vectorizer.fit_transform(X_train)\n",
        "X_test_counts = count_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "OnEyvyzqN0ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_counts, y_train)"
      ],
      "metadata": {
        "id": "ZyXyx7B2N8Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM)\n",
        "svm_model = SVC(kernel='linear', C=1)\n",
        "svm_model.fit(X_train_resampled, y_train_resampled)\n",
        "svm_predictions = svm_model.predict(X_test_counts)\n",
        "\n",
        "print(\"Support Vector Machine (SVM) Classification Report:\")\n",
        "print(classification_report(y_test, svm_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdPl21Gb-Rrg",
        "outputId": "135fe3ac-e0fb-40cb-d848-47f3f7199b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine (SVM) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.80      0.81       974\n",
            "           1       0.77      0.81      0.79       822\n",
            "\n",
            "    accuracy                           0.80      1796\n",
            "   macro avg       0.80      0.80      0.80      1796\n",
            "weighted avg       0.80      0.80      0.80      1796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing SVM on Individual platform datasets"
      ],
      "metadata": {
        "id": "-_LsqGi3aiqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load separate test datasets for Instagram and Twitter\n",
        "insta_test_df = pd.read_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/insta_test.csv')\n",
        "twitter_test_df = pd.read_csv('/content/drive/MyDrive/MSC Data science/Thesis/Final data/twitter_test.csv')\n",
        "\n",
        "# Mapping between class names and their corresponding integer labels\n",
        "class_mapping = {'cyberbullying': 0, 'non-cyberbullying': 1}\n",
        "\n",
        "# Convert labels to integers using the mapping\n",
        "insta_test_df['label'] = insta_test_df['label'].map(class_mapping)\n",
        "twitter_test_df['label'] = twitter_test_df['label'].map(class_mapping)"
      ],
      "metadata": {
        "id": "VMI26CaPYHG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization\n",
        "insta_test_vectorized = count_vectorizer.transform(insta_test_df['text'])\n",
        "twitter_test_vectorized = count_vectorizer.transform(twitter_test_df['text'])\n",
        "\n",
        "# Predict on test data\n",
        "insta_test_predictions = svm_model.predict(insta_test_vectorized)\n",
        "twitter_test_predictions = svm_model.predict(twitter_test_vectorized)\n",
        "\n",
        "# Evaluation\n",
        "insta_report = classification_report(insta_test_df['label'], insta_test_predictions)\n",
        "twitter_report = classification_report(twitter_test_df['label'], twitter_test_predictions)\n",
        "\n",
        "print(\"Instagram Test Report:\\n\", insta_report)\n",
        "print(\"Twitter Test Report:\\n\", twitter_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UGIQsaHTS-9",
        "outputId": "b5d8e839-875d-48ea-e2ae-34b62e0d4b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instagram Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.53      0.51       279\n",
            "           1       0.84      0.83      0.83       843\n",
            "\n",
            "    accuracy                           0.75      1122\n",
            "   macro avg       0.67      0.68      0.67      1122\n",
            "weighted avg       0.76      0.75      0.75      1122\n",
            "\n",
            "Twitter Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.85      0.89      6812\n",
            "           1       0.39      0.66      0.49       997\n",
            "\n",
            "    accuracy                           0.82      7809\n",
            "   macro avg       0.67      0.75      0.69      7809\n",
            "weighted avg       0.87      0.82      0.84      7809\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Count Vectorizer"
      ],
      "metadata": {
        "id": "006mrQ9maxFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "logreg_model = LogisticRegression(max_iter=1000, C=1)\n",
        "logreg_model.fit(X_train_resampled, y_train_resampled)\n",
        "logreg_predictions = logreg_model.predict(X_test_counts)\n",
        "\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, logreg_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg-Xa-Qj-RgE",
        "outputId": "0c23a2f7-e0db-4075-e6e0-fc3e6902b377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83       974\n",
            "           1       0.78      0.84      0.81       822\n",
            "\n",
            "    accuracy                           0.82      1796\n",
            "   macro avg       0.82      0.82      0.82      1796\n",
            "weighted avg       0.82      0.82      0.82      1796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Log Regression on Individual platform datasets"
      ],
      "metadata": {
        "id": "HFKt7BW9bHJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "insta_test_predictions = logreg_model.predict(insta_test_vectorized)\n",
        "twitter_test_predictions = logreg_model.predict(twitter_test_vectorized)\n",
        "\n",
        "# Evaluation\n",
        "insta_report = classification_report(insta_test_df['label'], insta_test_predictions)\n",
        "twitter_report = classification_report(twitter_test_df['label'], twitter_test_predictions)\n",
        "\n",
        "print(\"Instagram Test Report:\\n\", insta_report)\n",
        "print(\"Twitter Test Report:\\n\", twitter_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtMiPCM2bMY5",
        "outputId": "defe3df5-6133-4e10-c166-e7b482a17133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instagram Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.50      0.52       279\n",
            "           1       0.84      0.86      0.85       843\n",
            "\n",
            "    accuracy                           0.77      1122\n",
            "   macro avg       0.69      0.68      0.69      1122\n",
            "weighted avg       0.77      0.77      0.77      1122\n",
            "\n",
            "Twitter Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.85      0.90      6812\n",
            "           1       0.41      0.70      0.52       997\n",
            "\n",
            "    accuracy                           0.83      7809\n",
            "   macro avg       0.68      0.78      0.71      7809\n",
            "weighted avg       0.88      0.83      0.85      7809\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes Count Vectorizer"
      ],
      "metadata": {
        "id": "sY_py6SMbd39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "naive_bayes_model = MultinomialNB(alpha=1.0)\n",
        "naive_bayes_model.fit(X_train_resampled, y_train_resampled)\n",
        "naive_bayes_predictions = naive_bayes_model.predict(X_test_counts)\n",
        "\n",
        "print(\"Naive Bayes Classification Report:\")\n",
        "print(classification_report(y_test, naive_bayes_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhlm5aeO-RQH",
        "outputId": "9c54fc4f-6ef7-4b29-ed98-3cd162e19970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.80       974\n",
            "           1       0.76      0.79      0.77       822\n",
            "\n",
            "    accuracy                           0.79      1796\n",
            "   macro avg       0.79      0.79      0.79      1796\n",
            "weighted avg       0.79      0.79      0.79      1796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Naive Bayes on Individual Pltaform datasets"
      ],
      "metadata": {
        "id": "S-bL-TnSbmcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "insta_test_predictions = naive_bayes_model.predict(insta_test_vectorized)\n",
        "twitter_test_predictions = naive_bayes_model.predict(twitter_test_vectorized)\n",
        "\n",
        "# Evaluation\n",
        "insta_report = classification_report(insta_test_df['label'], insta_test_predictions)\n",
        "twitter_report = classification_report(twitter_test_df['label'], twitter_test_predictions)\n",
        "\n",
        "print(\"Instagram Test Report:\\n\", insta_report)\n",
        "print(\"Twitter Test Report:\\n\", twitter_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf9Ye_YNbr7k",
        "outputId": "ae22864e-73ab-4394-dbf6-0a8033984c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instagram Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.51      0.49       279\n",
            "           1       0.83      0.81      0.82       843\n",
            "\n",
            "    accuracy                           0.74      1122\n",
            "   macro avg       0.65      0.66      0.66      1122\n",
            "weighted avg       0.74      0.74      0.74      1122\n",
            "\n",
            "Twitter Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.87      0.90      6812\n",
            "           1       0.41      0.60      0.48       997\n",
            "\n",
            "    accuracy                           0.84      7809\n",
            "   macro avg       0.67      0.74      0.69      7809\n",
            "weighted avg       0.87      0.84      0.85      7809\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFIDF"
      ],
      "metadata": {
        "id": "VJOHR126SjQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Apply TF-IDF vectorization to text data\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # max_features\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "7WpISWR1TFaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "SbAF1POCSk6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM TFIDF MODEL"
      ],
      "metadata": {
        "id": "refYWtkUcRPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine (SVM)\n",
        "svm_model = SVC(kernel='linear', C=1)\n",
        "svm_model.fit(X_train_resampled, y_train_resampled)\n",
        "svm_predictions = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Support Vector Machine (SVM) Classification Report:\")\n",
        "print(classification_report(y_test, svm_predictions))"
      ],
      "metadata": {
        "id": "fSWUmmLLSxv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a074731d-af39-438b-becd-bea4b12d5590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support Vector Machine (SVM) Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82       974\n",
            "           1       0.77      0.85      0.80       822\n",
            "\n",
            "    accuracy                           0.81      1796\n",
            "   macro avg       0.81      0.81      0.81      1796\n",
            "weighted avg       0.82      0.81      0.81      1796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing SVM on platform datasets"
      ],
      "metadata": {
        "id": "DBvqYsexcUwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "insta_test_predictions = svm_model.predict(insta_test_vectorized)\n",
        "twitter_test_predictions = svm_model.predict(twitter_test_vectorized)\n",
        "\n",
        "# Evaluation\n",
        "insta_report = classification_report(insta_test_df['label'], insta_test_predictions)\n",
        "twitter_report = classification_report(twitter_test_df['label'], twitter_test_predictions)\n",
        "\n",
        "print(\"Instagram Test Report:\\n\", insta_report)\n",
        "print(\"Twitter Test Report:\\n\", twitter_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGjIjhUKcZLo",
        "outputId": "c15d2239-93c3-4504-c1ed-383fe7faedb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instagram Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.75      0.53       279\n",
            "           1       0.89      0.65      0.75       843\n",
            "\n",
            "    accuracy                           0.68      1122\n",
            "   macro avg       0.65      0.70      0.64      1122\n",
            "weighted avg       0.77      0.68      0.70      1122\n",
            "\n",
            "Twitter Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.94      0.93      6812\n",
            "           1       0.48      0.41      0.44       997\n",
            "\n",
            "    accuracy                           0.87      7809\n",
            "   macro avg       0.70      0.67      0.68      7809\n",
            "weighted avg       0.86      0.87      0.86      7809\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log Reg TFIDF"
      ],
      "metadata": {
        "id": "LnsJvh_KcwS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "logreg_model = LogisticRegression(max_iter=1000, C=1)\n",
        "logreg_model.fit(X_train_resampled, y_train_resampled)\n",
        "logreg_predictions = logreg_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, logreg_predictions))"
      ],
      "metadata": {
        "id": "2Cn3Ik3ZS0Qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75b3e1b-7c76-48f0-ceb5-9fdac590daa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.83       974\n",
            "           1       0.77      0.85      0.81       822\n",
            "\n",
            "    accuracy                           0.82      1796\n",
            "   macro avg       0.82      0.82      0.82      1796\n",
            "weighted avg       0.82      0.82      0.82      1796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Log Reg on Individual platform datasets"
      ],
      "metadata": {
        "id": "4riKExpNc88T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "insta_test_predictions = logreg_model.predict(insta_test_vectorized)\n",
        "twitter_test_predictions = logreg_model.predict(twitter_test_vectorized)\n",
        "\n",
        "# Evaluation\n",
        "insta_report = classification_report(insta_test_df['label'], insta_test_predictions)\n",
        "twitter_report = classification_report(twitter_test_df['label'], twitter_test_predictions)\n",
        "\n",
        "print(\"Instagram Test Report:\\n\", insta_report)\n",
        "print(\"Twitter Test Report:\\n\", twitter_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI8vckVUdCHb",
        "outputId": "4c44601b-4a8e-45c0-c840-ff734fb573f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instagram Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.41      0.77      0.54       279\n",
            "           1       0.90      0.64      0.74       843\n",
            "\n",
            "    accuracy                           0.67      1122\n",
            "   macro avg       0.65      0.71      0.64      1122\n",
            "weighted avg       0.78      0.67      0.69      1122\n",
            "\n",
            "Twitter Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.93      6812\n",
            "           1       0.49      0.39      0.44       997\n",
            "\n",
            "    accuracy                           0.87      7809\n",
            "   macro avg       0.70      0.67      0.68      7809\n",
            "weighted avg       0.86      0.87      0.86      7809\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes TFIDF"
      ],
      "metadata": {
        "id": "ubYKNRyydKKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "naive_bayes_model = MultinomialNB(alpha=1.0)\n",
        "naive_bayes_model.fit(X_train_resampled, y_train_resampled)\n",
        "naive_bayes_predictions = naive_bayes_model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Naive Bayes Classification Report:\")\n",
        "print(classification_report(y_test, naive_bayes_predictions))"
      ],
      "metadata": {
        "id": "NO9_pi7dS3cF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d303b22-8e20-4029-cae2-6c1922879aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.84      0.82       974\n",
            "           1       0.80      0.74      0.77       822\n",
            "\n",
            "    accuracy                           0.80      1796\n",
            "   macro avg       0.80      0.79      0.79      1796\n",
            "weighted avg       0.80      0.80      0.79      1796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Naive Bayes on Individual platform datasets"
      ],
      "metadata": {
        "id": "LSgQMGgzdPg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "insta_test_predictions = naive_bayes_model.predict(insta_test_vectorized)\n",
        "twitter_test_predictions = naive_bayes_model.predict(twitter_test_vectorized)\n",
        "\n",
        "# Evaluation\n",
        "insta_report = classification_report(insta_test_df['label'], insta_test_predictions)\n",
        "twitter_report = classification_report(twitter_test_df['label'], twitter_test_predictions)\n",
        "\n",
        "print(\"Instagram Test Report:\\n\", insta_report)\n",
        "print(\"Twitter Test Report:\\n\", twitter_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz9VlNMhdbP0",
        "outputId": "936587d6-a506-4a36-bcb6-c78cd51c3af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instagram Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.63      0.53       279\n",
            "           1       0.86      0.75      0.80       843\n",
            "\n",
            "    accuracy                           0.72      1122\n",
            "   macro avg       0.66      0.69      0.67      1122\n",
            "weighted avg       0.76      0.72      0.74      1122\n",
            "\n",
            "Twitter Test Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.91      6812\n",
            "           1       0.43      0.51      0.46       997\n",
            "\n",
            "    accuracy                           0.85      7809\n",
            "   macro avg       0.68      0.70      0.69      7809\n",
            "weighted avg       0.86      0.85      0.86      7809\n",
            "\n"
          ]
        }
      ]
    }
  ]
}